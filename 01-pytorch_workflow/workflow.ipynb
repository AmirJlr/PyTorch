{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f473b857",
   "metadata": {},
   "source": [
    "## Sample Workflow :\n",
    "\n",
    "- ### 1: data (prepare and load)\n",
    "- ### 2: bulid model\n",
    "- ### 3: fitting the model to data (Training)\n",
    "- ### 4: making prediction and evaluating a model\n",
    "- ### 5: saving amd loading a model\n",
    "- ### 6: putting it all togother\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74894363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn # nn contains all pytorch building blocks for neural networks\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e9eaa",
   "metadata": {},
   "source": [
    "- ### Data: Preparig and loading\n",
    "\n",
    "#### data can be almost anything...\n",
    "* Tabular data\n",
    "* Images\n",
    "* Videos\n",
    "* Audio\n",
    "* DNA\n",
    "* Text\n",
    "\n",
    "Machine learning is a game of two parts:\n",
    "1. Get data into numerical representation.\n",
    "2. Build Proper Model For learning that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e2830",
   "metadata": {},
   "source": [
    "### Use linear regression formula to make a straight line with **known parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e9f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73854ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0200, 0.0400, 0.0600, 0.0800])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "X = torch.arange(start, end, step)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d44e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5073ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0200],\n",
       "        [0.0400],\n",
       "        [0.0600],\n",
       "        [0.0800]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.unsqueeze(dim=1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af4af74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521b7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X * weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227e679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f094ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### spliting data into train and test sets ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd971728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d3375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize our data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1747a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(train_data=X_train, train_labels=y_train,\n",
    "                    test_data=X_test, test_labels=y_test, \n",
    "                    predictions=None):\n",
    "    \"\"\"\n",
    "    plot training and test data and compare them with predictions\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    # trainind data\n",
    "    plt.scatter(train_data, train_labels, c='b', s=4, label='Training data')\n",
    "    # test data\n",
    "    plt.scatter(test_data, test_labels, c='r', s=4, label='Testing data')\n",
    "    \n",
    "    # plot the predictions if they exists:\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c='g', s=4, label='Predictions')\n",
    "         \n",
    "            \n",
    "    plt.legend();\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70fc1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_prediction();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee2975",
   "metadata": {},
   "source": [
    "- ### Building first Model\n",
    "\n",
    "our model :\n",
    "- Start with random values\n",
    "- Look at tgraining data\n",
    "- Adjust random values to better represent(or get closer to) the ideal values\n",
    "\n",
    "How to adjust?\n",
    "- 1. Gradient decent\n",
    "- 2. BackPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0547ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Linear Regressin Python Classes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a16169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.rand(1, dtype=torch.float, requires_grad=True))\n",
    "        self.bias = nn.Parameter(torch.rand(1, dtype=torch.float, requires_grad=True))\n",
    "        \n",
    "    # Forward method to define computation in the model :\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor: # x is the input data\n",
    "        return self.weights * x + self.bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48fe087",
   "metadata": {},
   "source": [
    "### PyTorch model building essentials :\n",
    "\n",
    "- **torch.nn** --> contains all of the buildings for computational graphs (Neurak Networks)\n",
    "\n",
    "- **torch.nn.Parameter** --> (what paramater should our model try and learn, often a pytorch layer from torch.nn will set this for us)\n",
    "\n",
    "- **torch.nn.Module** --> The base class for all neural network modules, if cubclass it, forward() should be overwrited.\n",
    "\n",
    "- **torch.optim** --> this is where the optimizers in pytorch live, they will help with gradient decent\n",
    "\n",
    "- **def forward()** --> feed forward in network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3563d497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.8823], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9150], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking the contents of our PyTorch model :\n",
    "\n",
    "# create a random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd045a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.8823])), ('bias', tensor([0.9150]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list named parameter\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "489c6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8000],\n",
       "         [0.8200],\n",
       "         [0.8400],\n",
       "         [0.8600],\n",
       "         [0.8800],\n",
       "         [0.9000],\n",
       "         [0.9200],\n",
       "         [0.9400],\n",
       "         [0.9600],\n",
       "         [0.9800]]),\n",
       " tensor([[0.8600],\n",
       "         [0.8740],\n",
       "         [0.8880],\n",
       "         [0.9020],\n",
       "         [0.9160],\n",
       "         [0.9300],\n",
       "         [0.9440],\n",
       "         [0.9580],\n",
       "         [0.9720],\n",
       "         [0.9860]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4cad3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6208],\n",
       "        [1.6385],\n",
       "        [1.6561],\n",
       "        [1.6738],\n",
       "        [1.6914],\n",
       "        [1.7090],\n",
       "        [1.7267],\n",
       "        [1.7443],\n",
       "        [1.7620],\n",
       "        [1.7796]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions with model:\n",
    "with torch.inference_mode():\n",
    "     y_preds=model_0(X_test)\n",
    "        \n",
    "y_preds\n",
    "\n",
    "\n",
    "## equivalent :\n",
    "# with torch.no_grad():\n",
    "#     y_preds=model_0(X_test)\n",
    "    \n",
    "# y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7329c4",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "start with random parameters and learn from data to get better representation.\n",
    "\n",
    "One way to measure how poor model prediction are is to use **Loss Function(Cost Function/ Criterion)**.\n",
    "\n",
    "\n",
    "Things we need to train:\n",
    "- Loss Function\n",
    "- Optimizer (adjust parameter base on loss to improve the Loss Function)\n",
    "\n",
    "In pytorch we need :\n",
    "- Training Loop\n",
    "- Testing Loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe3613d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup an optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2781de",
   "metadata": {},
   "source": [
    "### Building a Training Loop(and Testing Loop) in pytorch\n",
    "\n",
    "Things we need in training loop:\n",
    "\n",
    "0. Loop through the data\n",
    "1. Forward pass(this involves data moving through our models `forward()` functions)\n",
    "2. Calculate the Loss\n",
    "3. Optimizer zero grad\n",
    "4. Loss Backward - move backwards through the networks **Backpropagation**\n",
    "5. Optimizer Step - use optimizer to adjust model parameters. **Gradient Decent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00e436a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.8823])), ('bias', tensor([0.9150]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight = 0.7\n",
    "# bias = 0.3\n",
    "\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed5d5008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | Loss : 0.6860889196395874 | Test Loss : 0.7637526988983154\n",
      "OrderedDict([('weights', tensor([0.8784])), ('bias', tensor([0.9050]))])\n",
      "\n",
      "Epoch : 10 | Loss : 0.5708791017532349 | Test Loss : 0.6290428042411804\n",
      "OrderedDict([('weights', tensor([0.8394])), ('bias', tensor([0.8050]))])\n",
      "\n",
      "Epoch : 20 | Loss : 0.45566922426223755 | Test Loss : 0.4943329691886902\n",
      "OrderedDict([('weights', tensor([0.8004])), ('bias', tensor([0.7050]))])\n",
      "\n",
      "Epoch : 30 | Loss : 0.34045934677124023 | Test Loss : 0.35962313413619995\n",
      "OrderedDict([('weights', tensor([0.7614])), ('bias', tensor([0.6050]))])\n",
      "\n",
      "Epoch : 40 | Loss : 0.2252494841814041 | Test Loss : 0.2249133139848709\n",
      "OrderedDict([('weights', tensor([0.7224])), ('bias', tensor([0.5050]))])\n",
      "\n",
      "Epoch : 50 | Loss : 0.1100396141409874 | Test Loss : 0.09020347893238068\n",
      "OrderedDict([('weights', tensor([0.6834])), ('bias', tensor([0.4050]))])\n",
      "\n",
      "Epoch : 60 | Loss : 0.009724985808134079 | Test Loss : 0.020998019725084305\n",
      "OrderedDict([('weights', tensor([0.6539])), ('bias', tensor([0.3200]))])\n",
      "\n",
      "Epoch : 70 | Loss : 0.006216754671186209 | Test Loss : 0.014099234715104103\n",
      "OrderedDict([('weights', tensor([0.6707])), ('bias', tensor([0.3120]))])\n",
      "\n",
      "Epoch : 80 | Loss : 0.002788322512060404 | Test Loss : 0.005826681852340698\n",
      "OrderedDict([('weights', tensor([0.6878])), ('bias', tensor([0.3050]))])\n",
      "\n",
      "Epoch : 90 | Loss : 0.007095950655639172 | Test Loss : 0.00754010071977973\n",
      "OrderedDict([('weights', tensor([0.6938])), ('bias', tensor([0.2980]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #set the model to training mode\n",
    "    model_0.train() # track requires gradient\n",
    "    \n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "    \n",
    "    # 2. Loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # 3. optimizer zero grad\n",
    "    optimizer.zero_grad() # if not; going to exploding gradient\n",
    "    \n",
    "    # 4. Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Step Optimizer\n",
    "    optimizer.step()\n",
    "     \n",
    "    ### Testing\n",
    "    model_0.eval() # turns off different settings in the model not needed for evaluating/testing.\n",
    "\n",
    "    with torch.inference_mode():# turns off gradient tracking & couple more things\n",
    "        # 1. Forward Pass\n",
    "        test_pred = model_0(X_test)\n",
    "        \n",
    "        # 2. Loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "        \n",
    "    # Output\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "        \n",
    "        print(f\"Epoch : {epoch} | Loss : {loss} | Test Loss : {test_loss}\")\n",
    "        print(model_0.state_dict())\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3036059",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds_new = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f67cf31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_prediction(predictions=y_preds_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c512cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6861, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5709, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4557, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3405, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2252, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1100, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0097, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0062, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0028, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0071, grad_fn=<MeanBackward0>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc28fe39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6860889 , 0.5708791 , 0.45566922, 0.34045935, 0.22524948,\n",
       "       0.11003961, 0.00972499, 0.00621675, 0.00278832, 0.00709595],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_loss_values).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25e27a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.plot(epoch_count, torch.tensor(train_loss_values).numpy(), label = 'Train Loss')\\nplt.plot(epoch_count, torch.tensor(test_loss_values).numpy(), label = 'Test Loss')\\n\\nplt.xlabel('Epochs')\\nplt.ylabel('Loss')\\n\\nplt.title('Train and Test Loss Values')\\nplt.legend();\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.plot(epoch_count, torch.tensor(train_loss_values).numpy(), label = 'Train Loss')\n",
    "plt.plot(epoch_count, torch.tensor(test_loss_values).numpy(), label = 'Test Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.title('Train and Test Loss Values')\n",
    "plt.legend();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd9c3c",
   "metadata": {},
   "source": [
    "- ### Save & Load The Model\n",
    "\n",
    "3 main methods for saving/loading models in PyTorch :\n",
    "- 1. `torch.save()` - save a PyTorch objects in python pickle format\n",
    "\n",
    "- 2. `torch.load()` - load a saved PyTorch object.\n",
    "\n",
    "- 3. `torch.nn.Module.load_state_dict()` - load a model's saved state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5edd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recommended in Pytorch Documentation :\n",
    "\n",
    "# save :\n",
    "from pathlib import Path\n",
    "\n",
    "# create directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# saving :\n",
    "MODEL_NAME = '01_workflow_0.pth'\n",
    "torch.save(model_0.state_dict(), f\"{MODEL_PATH}/{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5173e2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load :\n",
    "my_model_1 = LinearRegressionModel()\n",
    "my_model_1.load_state_dict(torch.load(f\"{MODEL_PATH}/{MODEL_NAME}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8aa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
